{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn\n",
    "\n",
    "Miguel Ángel Jiménez Cuadrillero\n",
    "7/5/2020\n",
    "\n",
    "## Creación y evaluación de modelos predictivos en python con Scikit-learn\n",
    "\n",
    "\n",
    "### ¿Cómo instalar scikit-learn?\n",
    "\n",
    "pip install scikit-learn\n",
    "\n",
    "\n",
    "## Cómo crear un modelo simple\n",
    "\n",
    "Para este ejemplo utilizaremos el archiconocido iris dataset y un tipo de modelo simple con un único hiperparámetro: usaremos un clasificador k-neighbours con n_neighbors=1. Este es un modelo muy simple e intuitivo que dice \"la etiqueta de un punto desconocido es la misma que la etiqueta de su punto de entrenamiento más cercano\"\n",
    "\n",
    "## Cargar Dataset\n",
    "\n",
    "\n",
    "Información del conjunto de datos:\n",
    "\n",
    "Esta es quizás la base de datos más conocida que se encuentra en la literatura de Machine Learning. El conjunto de datos contiene 3 clases de 50 instancias cada una, donde cada clase se refiere a un tipo de planta de iris. Una clase es linealmente separable de las otras 2; estos últimos NO son linealmente separables entre sí.\n",
    "\n",
    "Atributo previsto: clase de planta de iris.\n",
    "\n",
    "Información de los atributos:\n",
    "\n",
    "* longitud del sépalo en cm\n",
    "* ancho del sépalo en cm\n",
    "* longitud del pétalo en cm\n",
    "* ancho del pétalo en cm\n",
    "* clase:\n",
    "    - Iris Setosa\n",
    "    - Iris Versicolour\n",
    "    - Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.669160Z",
     "start_time": "2020-06-07T13:39:51.652713Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear un modelo simple, en primer lugar debemos saber si es de clasificación o de regresión y con esa información buscar la clase que represente al tipo de modelo en la siguiente API:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "\n",
    "En este caso buscamos el clasificador KNeighborsClassifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.828148Z",
     "start_time": "2020-06-07T13:39:52.674116Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1) #Configuramos el hiperparámetro para tener la línea base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.845158Z",
     "start_time": "2020-06-07T13:39:52.830152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos de entrenamiento\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.865161Z",
     "start_time": "2020-06-07T13:39:52.847149Z"
    }
   },
   "outputs": [],
   "source": [
    "#Realizamos predicciones en base a los datos de entrenamiento.\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.880189Z",
     "start_time": "2020-06-07T13:39:52.871161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo precisión de 1.0, lo que indica que nuestro modelo etiquetó correctamente el 100% de los puntos\n",
    "\n",
    "¿Pero esto realmente mide la precisión esperada? ¿Realmente hemos encontrado un modelo que esperamos sea correcto el 100% las veces?\n",
    "\n",
    "La respuesta es no y es por un error fundamental: se entrena y evalúa el modelo con los mismos datos . Además, el modelo K-nearest neigbours es un estimador basado en instancias que simplemente almacena los datos de entrenamiento y predice las etiquetas comparando datos nuevos con estos puntos almacenados: siempre dará 100% si consultamos por los datos con los que entrenamos.\n",
    "\n",
    "## Cómo usar la validación cruzada o Cross Validation para evitar el sobreajuste\n",
    "\n",
    "### Validación del modelo mediante Holdout sets\n",
    "\n",
    "Para tener una mejor idea de lo bueno que es el modelo, se utilizan los datos de validación, es decir, hold-out set: retenemos un subconjunto de los datos del entrenamiento del modelo y luego usamos este conjunto para verificar el rendimiento del modelo. \n",
    "\n",
    "Esta división se puede hacer usando la train_test_splitutilidad en Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.905153Z",
     "start_time": "2020-06-07T13:39:52.886163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data with 50% in each set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y_predicted = model.predict(X_test)\n",
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos aquí un resultado más razonable: el clasificador del vecino más cercano tiene una precisión del 90% en este  hold-out set. El conjunto de retención es similar a datos desconocidos, porque el modelo no lo ha \"visto\" antes.\n",
    "\n",
    "## Validación del modelo mediante Cross-Validation\n",
    "\n",
    "\n",
    "Una desventaja de usar un conjunto de reserva para la validación del modelo es que hemos perdido una parte de nuestros datos en el entrenamiento del modelo. En el caso anterior, ¡la mitad del conjunto de datos no contribuye a la capacitación del modelo! Esto no es óptimo y puede causar problemas, especialmente si el conjunto inicial de datos de entrenamiento es pequeño (como es el caso)\n",
    "\n",
    "Una forma de abordar esto es utilizar la validación cruzada ; es decir, hacer una secuencia de ajustes donde cada subconjunto de datos se usa como un conjunto de entrenamiento y como un conjunto de validación.\n",
    "\n",
    "Vamos a hacer una prueba usando la mitad de los datos como entrenamiento y como test alternativamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.930175Z",
     "start_time": "2020-06-07T13:39:52.909668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, 0.9066666666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_model = model.fit(X_train, y_train).predict(X_test)\n",
    "y1_model = model.fit(X_test, y_test).predict(X_train)\n",
    "accuracy_score(y_train, y1_model), accuracy_score(y_test, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que sale son dos puntajes de precisión distintos, que podríamos combinar (por ejemplo, tomando la media) para obtener una mejor medición del rendimiento del modelo global. Esta forma particular de validación cruzada es una validación cruzada doble, es decir, una en la que hemos dividido los datos en dos conjuntos y los hemos utilizado a su vez como un conjunto de validación y entrenamiento.\n",
    "\n",
    "Podríamos ampliar esta idea para usar aún más pruebas y más pliegues en los datos --> K-fold Cross Validation\n",
    "\n",
    "Scikit Learn ya tiene mecanismos para este tipo de entrenamiento y estimación de prestaciones: *cross_val_score*\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "Este método nos dará la evaluación de la métrica que definamos, y en el caso de no estar definida, será la que tenga por defecto el estimador. Al ser un modelo de clasificación la métrica por defecto es *accuracy*\n",
    "\n",
    "Otras métricas:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "*cross_validate* es similar pero permite evaluar varias métricas:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:52.963174Z",
     "start_time": "2020-06-07T13:39:52.936196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La repetición de la validación en diferentes subconjuntos de datos nos da una idea aún mejor del rendimiento del algoritmo.\n",
    "\n",
    "Scikit-Learn implementa una serie de esquemas útiles de validación cruzada que son útiles en situaciones particulares; Estos se implementan a través de iteradores en el módulo *\"sklearn.model_selection\"* (antoguo cross_validation). \n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n",
    "\n",
    "Por ejemplo, podríamos desear llegar al caso extremo en el que nuestro número de pliegues es igual al número de puntos de datos: es decir, entrenamos en todos los puntos menos uno en cada prueba. Este tipo de validación cruzada se conoce como validación cruzada LeaveOneOut y se puede utilizar de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.263268Z",
     "start_time": "2020-06-07T13:39:52.965176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores = cross_val_score(model, X, y, cv=LeaveOneOut())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.271294Z",
     "start_time": "2020-06-07T13:39:53.264270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#media de las puntuaciones:\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas\n",
    "\n",
    "Una gran parte del trabajo de un data scientist es evaluar modelos de forma correcta. En el siguiente tenemos una explicación de las métricas que podemos utilizar para evaluar el performance de los modelos que creemos.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo encontrar los mejores parámetros para su modelo elegido?\n",
    "\n",
    "Un punto importante es que una clase de modelo no es lo mismo que una instancia de un modelo.\n",
    "\n",
    "Una vez que hayamos decidido nuestra clase de modelo, todavía hay algunas opciones disponibles que tenemos que configurar. Dependiendo de la clase de modelo con la que estamos trabajando, es posible que necesitemos responder una o más preguntas como las siguientes:\n",
    "\n",
    "* ¿Nos gustaría ajustar el desplazamiento (es decir, la intersección con el eje y)?\n",
    "* ¿Nos gustaría que el modelo se normalice?\n",
    "* ¿Nos gustaría preprocesar nuestras funciones para agregar flexibilidad al modelo?\n",
    "* ¿Qué grado de regularización nos gustaría utilizar en nuestro modelo?\n",
    "* ...\n",
    "\n",
    "\n",
    "Estos son ejemplos de las elecciones importantes que deben hacerse una vez que se selecciona la clase de modelo. Estas opciones a menudo se representan como hiperparámetros o parámetros que deben establecerse antes de que el modelo se ajuste a los datos.\n",
    "\n",
    "En Scikit-Learn, los hiperparámetros se eligen pasando valores en la instanciación del modelo. \n",
    "\n",
    "En nuestro caso el hiperparámetro que podemos configurar es valor de K, vamos a hacer un barrido sobre los datos mediante cross validation y variando el valor de K para encontrar la mejor combinación (en este caso sólo un valor) de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.283269Z",
     "start_time": "2020-06-07T13:39:53.275306Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {'n_neighbors': [1,2,3,4,5,6,7]}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.423839Z",
     "start_time": "2020-06-07T13:39:53.289269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(n_neighbors=1),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.431000Z",
     "start_time": "2020-06-07T13:39:53.426010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.450010Z",
     "start_time": "2020-06-07T13:39:53.433000Z"
    }
   },
   "outputs": [],
   "source": [
    "#utilizamos el mejor modelo\n",
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T13:39:53.480288Z",
     "start_time": "2020-06-07T13:39:53.457004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "203px",
    "width": "576px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
